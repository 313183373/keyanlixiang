# 使用方法
1. 需要安装mongodb和redis数据库，其中所有词条是存在redis中的，然后结果是放在mongodb里面的。
2. 如果第一次运行的话，也就是redis中没有条目的话，确保NormalizedGoogleDistance.js里面的redisSaver.saveData(data)及以上的代码没有注释，然后把下面的代码注释掉，函数定义不需要注释，然后运行就可以了，这一步是往redis里面存所有的条目
3. 已经运行过一次之后，就不需要`从excel中获取数据`和`将获取到的词条存到redis中`这两部分代码,然后确保运行getAllData()函数，这个是从百度获取数据的函数。
4. 获取数据的时候，可能会出现结果数目是空的情况，在所有词条都获取完了之后，再注释掉getAllData()函数，然后再运行fixNullNumber()函数，会找出mongodb中所有number=null的词条，然后重新获取数据。
5. 等待所有数据获取完了之后，再只需要运行saveDataToExcel（）那个函数就行了，结果会存在excel里面。（其实存不存到excel没有关系，mongodb数据里也有）

6. 所有词条的结果获取之后，可以运行calcNBD.js程序，他会从mongodb里面获取结果然后计算NBD，最后将结果存入excel nbdx.xlsx中，如果打开出现错误，就打开修复。


ps:第三步可能需要多次执行，可能由于网络的原因，导致爬取速度越来越慢，然后会出现一个一个的爬取甚至卡死的情况，如果发现了爬取速度变慢了（最开始是10个一起爬），就重新运行程序，已经爬过的词条他会先滤除掉，不会重复爬取。
pps:如果百度搜索的规则变了，那么需要就更改的一下爬虫里面百度的内容吧。




